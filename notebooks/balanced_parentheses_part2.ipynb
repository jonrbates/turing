{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Balanced Parentheses Problem\n",
    "### and a transformer solution (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from turing.translators import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st     tensor([0., 0., 1., 0., 0., 0.]) M\n",
      "sym1   tensor([1., 0., 0., 0., 0.]) (\n",
      "sym2   tensor([0., 0., 0., 0., 0.]) UNK\n",
      "pos1   tensor([0., 0., 1., 0.]) 2\n",
      "pos2   tensor([0., 0., 1., 1.]) 3\n",
      "pos3   tensor([0., 0., 0., 0.]) 0\n",
      "scr1   tensor([0., 0., 0., 0., 0.]) UNK\n",
      "scr2   tensor([0., 0., 0., 0., 0.]) UNK\n",
      "scr3   tensor([0., 0., 0., 0.]) 0\n",
      "scr4   tensor([0., 0., 0.]) None\n",
      "scr5   tensor([0., 0.]) None\n"
     ]
    }
   ],
   "source": [
    "tx = Translator(T=10)\n",
    "tx.projecto(tx.h(\"M\", \"(\", 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim C.4 and C.5\n",
    "\n",
    "Let's suppose we're about to visit position l=3 at step 5. The last time we visited this position was when at step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "pos1   tensor([0., 0., 0., 0.]) 0\n",
      "pos2   tensor([0., 0., 0., 0.]) 0\n",
      "pos3   tensor([0., 0., 0., 1.]) 1\n",
      "1\n",
      "pos1   tensor([0., 0., 0., 1.]) 1\n",
      "pos2   tensor([0., 0., 0., 1.]) 1\n",
      "pos3   tensor([0., 0., 1., 0.]) 2\n",
      "2\n",
      "pos1   tensor([0., 0., 1., 0.]) 2\n",
      "pos2   tensor([0., 0., 1., 0.]) 2\n",
      "pos3   tensor([0., 0., 1., 1.]) 3\n",
      "3\n",
      "pos1   tensor([0., 0., 1., 1.]) 3\n",
      "pos2   tensor([0., 0., 1., 1.]) 3\n",
      "pos3   tensor([0., 0., 1., 0.]) 2\n",
      "4\n",
      "pos1   tensor([0., 1., 0., 0.]) 4\n",
      "pos2   tensor([0., 0., 1., 0.]) 2\n",
      "pos3   tensor([0., 0., 1., 1.]) 3\n"
     ]
    }
   ],
   "source": [
    "# We'll ignore some of the subspaces for now:\n",
    "# TODO: clarify 0-indexing for meaning of step, etc.\n",
    "step = 5\n",
    "H = torch.zeros(step, tx.w)  # H = (h_0, h_1, ..., h_{step-1})\n",
    "path = [0, 1, 2, 3, 2, 3]\n",
    "for t in range(step):\n",
    "    print(t)\n",
    "    H[t, tx.pos1_:tx.pos2_] = torch.Tensor(tx.Bin(t))\n",
    "    H[t, tx.pos2_:tx.pos3_] = torch.Tensor(tx.Bin(path[t]))\n",
    "    H[t, tx.pos3_:tx.scr1_] = torch.Tensor(tx.Bin(path[t+1]))\n",
    "    tx.projecto(H[t,:], subspaces=[\"pos1\", \"pos2\", \"pos3\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B()((()(()))())E\n",
      "I ^                \n",
      "  B()((()(()))())E\n",
      "R  ^               \n",
      "  B()((()(()))())E\n",
      "R   ^              \n",
      "  B(*((()(()))())E\n",
      "M  ^               \n",
      "  B**((()(()))())E\n",
      "R   ^              \n",
      "  B**((()(()))())E\n",
      "R    ^             \n",
      "  B**((()(()))())E\n",
      "R     ^            \n",
      "  B**((()(()))())E\n",
      "R      ^           \n",
      "  B**((()(()))())E\n",
      "R       ^          \n",
      "  B**(((*(()))())E\n",
      "M      ^           \n",
      "  B**((**(()))())E\n",
      "R       ^          \n",
      "  B**((**(()))())E\n",
      "R        ^         \n",
      "  B**((**(()))())E\n",
      "R         ^        \n",
      "  B**((**(()))())E\n",
      "R          ^       \n",
      "  B**((**((*))())E\n",
      "M         ^        \n",
      "  B**((**(**))())E\n",
      "R          ^       \n",
      "  B**((**(**))())E\n",
      "R           ^      \n",
      "  B**((**(***)())E\n",
      "M          ^       \n",
      "  B**((**(***)())E\n",
      "M         ^        \n",
      "  B**((**(***)())E\n",
      "M        ^         \n",
      "  B**((******)())E\n",
      "R         ^        \n",
      "  B**((******)())E\n",
      "R          ^       \n",
      "  B**((******)())E\n",
      "R           ^      \n",
      "  B**((******)())E\n",
      "R            ^     \n",
      "  B**((*******())E\n",
      "M           ^      \n",
      "  B**((*******())E\n",
      "M          ^       \n",
      "  B**((*******())E\n",
      "M         ^        \n",
      "  B**((*******())E\n",
      "M        ^         \n",
      "  B**((*******())E\n",
      "M       ^          \n",
      "  B**((*******())E\n",
      "M      ^           \n",
      "  B**((*******())E\n",
      "M     ^            \n",
      "  B**(********())E\n",
      "R      ^           \n",
      "  B**(********())E\n",
      "R       ^          \n",
      "  B**(********())E\n",
      "R        ^         \n",
      "  B**(********())E\n",
      "R         ^        \n",
      "  B**(********())E\n",
      "R          ^       \n",
      "  B**(********())E\n",
      "R           ^      \n",
      "  B**(********())E\n",
      "R            ^     \n",
      "  B**(********())E\n",
      "R             ^    \n",
      "  B**(********())E\n",
      "R              ^   \n",
      "  B**(********(*)E\n",
      "M             ^    \n",
      "  B**(**********)E\n",
      "R              ^   \n",
      "  B**(**********)E\n",
      "R               ^  \n",
      "  B**(***********E\n",
      "M              ^   \n",
      "  B**(***********E\n",
      "M             ^    \n",
      "  B**(***********E\n",
      "M            ^     \n",
      "  B**(***********E\n",
      "M           ^      \n",
      "  B**(***********E\n",
      "M          ^       \n",
      "  B**(***********E\n",
      "M         ^        \n",
      "  B**(***********E\n",
      "M        ^         \n",
      "  B**(***********E\n",
      "M       ^          \n",
      "  B**(***********E\n",
      "M      ^           \n",
      "  B**(***********E\n",
      "M     ^            \n",
      "  B**(***********E\n",
      "M    ^             \n",
      "  B**************E\n",
      "R     ^            \n",
      "  B**************E\n",
      "R      ^           \n",
      "  B**************E\n",
      "R       ^          \n",
      "  B**************E\n",
      "R        ^         \n",
      "  B**************E\n",
      "R         ^        \n",
      "  B**************E\n",
      "R          ^       \n",
      "  B**************E\n",
      "R           ^      \n",
      "  B**************E\n",
      "R            ^     \n",
      "  B**************E\n",
      "R             ^    \n",
      "  B**************E\n",
      "R              ^   \n",
      "  B**************E\n",
      "R               ^  \n",
      "  B**************E\n",
      "R                ^ \n",
      "  B**************E\n",
      "V               ^  \n",
      "  B**************E\n",
      "V              ^   \n",
      "  B**************E\n",
      "V             ^    \n",
      "  B**************E\n",
      "V            ^     \n",
      "  B**************E\n",
      "V           ^      \n",
      "  B**************E\n",
      "V          ^       \n",
      "  B**************E\n",
      "V         ^        \n",
      "  B**************E\n",
      "V        ^         \n",
      "  B**************E\n",
      "V       ^          \n",
      "  B**************E\n",
      "V      ^           \n",
      "  B**************E\n",
      "V     ^            \n",
      "  B**************E\n",
      "V    ^             \n",
      "  B**************E\n",
      "V   ^              \n",
      "  B**************E\n",
      "V  ^               \n",
      "  B**************E\n",
      "V ^                \n",
      "  B**************E\n",
      "T  ^               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = Translator(T=83)\n",
    "tape = \"B()((()(()))())E\"\n",
    "tx.simulate(tape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WCMTranslator(\n",
       "  (transition): Transition(\n",
       "    (linear1): Linear(in_features=59, out_features=89, bias=True)\n",
       "    (linear2): Linear(in_features=89, out_features=59, bias=True)\n",
       "  )\n",
       "  (preprocess_for_adder): PreprocessForAdder(\n",
       "    (linear): Linear(in_features=59, out_features=66, bias=True)\n",
       "  )\n",
       "  (adder_layers): ModuleList(\n",
       "    (0): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (1): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (2): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (3): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (4): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (5): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (6): FullAdder(\n",
       "      (halfadder1): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (halfadder2): HalfAdder(\n",
       "        (linear_or_and): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (linear_or_not): Linear(in_features=66, out_features=66, bias=True)\n",
       "        (half_adder_final): Linear(in_features=66, out_features=66, bias=True)\n",
       "      )\n",
       "      (linear_or1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (linear_or2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (project_down): ProjectDown(\n",
       "    (project_down): Linear(in_features=66, out_features=59, bias=True)\n",
       "  )\n",
       "  (indicate_visited_position): IndicateVisitedPosition()\n",
       "  (binary_search_layers): ModuleList(\n",
       "    (0): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (1): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (2): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (3): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (4): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (5): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "    (6): BinarySearchStep(\n",
       "      (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (get_last_written_symbol): GetLastWrittenSymbol(\n",
       "    (linear): Linear(in_features=59, out_features=59, bias=False)\n",
       "  )\n",
       "  (get_initial_symbol): GetInitialSymbol()\n",
       "  (get_v): GetV(\n",
       "    (linear): Linear(in_features=59, out_features=59, bias=True)\n",
       "  )\n",
       "  (arrange_symbols): ArrangeSymbols(\n",
       "    (linear): Linear(in_features=59, out_features=59, bias=True)\n",
       "  )\n",
       "  (combine_symbols): CombineSymbols(\n",
       "    (linear_combine): Linear(in_features=59, out_features=59, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354509, 354509)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "def numel(m: torch.nn.Module, only_trainable: bool = False):\n",
    "    \"\"\"\n",
    "    returns the total number of parameters used by `m` (only counting\n",
    "    shared parameters once); if `only_trainable` is True, then only\n",
    "    includes parameters with `requires_grad = True`\n",
    "    \"\"\"\n",
    "    parameters = list(m.parameters())\n",
    "    if only_trainable:\n",
    "        parameters = [p for p in parameters if p.requires_grad]\n",
    "    unique = {p.data_ptr(): p for p in parameters}.values()\n",
    "    return sum(p.numel() for p in unique)\n",
    "\n",
    "numel(tx, False), numel(tx, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
